# DRRN



> [Deep reinforcement learning with a natural language action space](https://arxiv.org/abs/1511.04636)

本文介绍了一种新的强化学习体系结构，该体系结构采用深度神经网络，旨在处理基于文本的游戏中以自然语言为特征的状态和动作空间。这种体系结构被称为深度强化相关网络，它用独立的嵌入向量表示动作和状态空间，嵌入向量与交互功能相结合，在强化学习中接近Q函数。我们评估了DRRNon两个流行的文本游戏，展示了相对于其他深度问答学习架构的实验性能。解释动作描述的实验表明，该模型提取的是意义，而不是简单地记忆文本串。

## 方法

我们认为序贯决策提出了文本理解的问题。在每个步骤中，代理将接收描述状态的一串文本\(即“状态文本”\)和描述所有潜在关系的几串文本\(即“动作文本”\)。代理试图从状态和行为两个方面理解文本，衡量它们与当前上下文的相关性，以实现长期回报最大化，然后选择最佳行为。

![](../../.gitbook/assets/image%20%2882%29.png)

计算出每个动作的相关性后，可以得到策略：

![](../../.gitbook/assets/image%20%2884%29.png)

算法整体流程

![](../../.gitbook/assets/image%20%28124%29.png)

