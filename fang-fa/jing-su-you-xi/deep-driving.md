# Deep Driving

## 介绍

> [DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving](https://arxiv.org/pdf/1505.00256.pdf)

今天，基于视觉的自主驾驶系统有两种主要范例：间接感知方法，解析整个场景以制定驾驶决策，行为反射方法直接将输入图像映射到回归者的驾驶行为。 在本文中，我们提出了第三种范式：直接感知方法来估计驾驶能力。

我们建议将输入图像映射到与驾驶道路/交通状态的可供性直接相关的少量关键感知指标。我们的表示提供了一组完整但完整的场景描述，使一个简单的控制器能够自动驾驶。 介于感知和行为反射的两个极端之间，我们认为我们的直接感知表示提供了正确的抽象层次。为了证明这一点，我们使用视频游戏中12个小时的人类驾驶记录训练了一个深度卷积神经网络，并展示了我们的模型可以很好地在各种各样的虚拟环境中驾驶汽车。我们还在KITTI数据集上训练了一个车距估计模型。 结果表明，直接感知方法可以很好地推广到真实的图像。 源代码和数据可在我们的项目网站上找到。

![](../../.gitbook/assets/image%20%2817%29.png)

## 方法

当今大多数工业自主驾驶系统都是基于中介感知方法。在计算机视觉中，研究人员分别研究了每项任务。汽车检测和车道检测是自主驾驶系统的两个关键要素。典型算法输出检测到的汽车上的边界框和检测到的车道标记上的样条曲线。然而，这些边界框和样条不是我们用于驾驶的直接启示信息。因此，需要进行转换，这可能会导致额外的噪声。典型的车道检测算法，例如中提出的算法，都存在错误检测。具有刚性边界的结构（例如高速公路护栏或沥青表面裂缝）可能被错误识别为车道标记。即使车道检测结果良好，车辆定位的关键信息也可能丢失。例如，假设通常只能可靠地检测到两条车道标志，就很难确定一辆汽车是在双车道公路的左车道还是右车道上行驶。

![](../../.gitbook/assets/image%20%2857%29.png)

### Learning affordance for driving perception

为了有效地实现和测试我们的方法，我们使用了开源驱动游戏TORCS \(开放赛车模拟器\) \[ 21，它被广泛用于人工智能研究。





