# SLAM-Augmented DQN

## 介绍

> [Playing Doom with SLAM-Augmented Deep Reinforcement Learning](https://arxiv.org/pdf/1612.00380.pdf)

最近在2D游戏中进行策略学习的一些方法已经成功地直接从输入图像到动作。然而，当采用不复杂的3D环境时，它们通常会遇到与部分可观察性，组合探索空间，路径规划以及奖励方案稀缺相关的挑战。从先前的人类认知工作中汲取经验，这表明人类如何运用各种语义概念和抽象（对象类别，本地化等）来推理世界，我们建立了一个代理模型，将这种抽象结合到其策略学习框架中。我们通过添加所遇到的对象和结构元素的细节，以及代理的定位，来增加对深度问题学习网络\( DQN \)的原始图像输入。利用动态目标检测和三维场景重建，将不同的组件自动提取并组成拓扑表示。我们在《毁灭战士》中评估了我们的方法的有效性，这是一个三维的第一人称战斗游戏，展示了所讨论的许多挑战，并表明我们的增强框架不断地学习更好、更有效的策略。

## 方法

### Simultaneous Localization and Mapping

SLAM（Simultaneous Localization and Mapping），同步定位与地图构建，最早在机器人领域提出，它指的是：机器人从未知环境的未知地点出发，在运动过程中通过重复观测到的环境特征定位自身位置和姿态，再根据自身位置构建周围环境的增量式地图，从而达到同时定位和地图构建的目的。

通俗的来讲，SLAM回答两个问题：“我在哪儿？”“我周围是什么？”，就如同人到了一个陌生环境中一样，SLAM试图要解决的就是恢复出观察者自身和周围环境的相对空间关系，“我在哪儿”对应的就是定位问题，而“我周围是什么”对应的就是建图问题，给出周围环境的一个描述。回答了这两个问题，其实就完成了对自身和周边环境的空间认知。有了这个基础，就可以进行路径规划去达要去的目的地，在此过程中还需要及时的检测躲避遇到的障碍物，保证运行安全。

[视觉SLAM14讲](https://www.bilibili.com/video/av19397094?from=search&seid=4257257031966068730)

### Object detection

如图\(b\)即目标检测，神经网络需预测目标的类型以及所在区域。

![](../../.gitbook/assets/image%20%283%29.png)

[目标检测](https://github.com/hijkzzz/deep-learning/blob/master/juan-ji-wang-luo/mu-biao-jian-ce/README.md)

### Semantic Mapping

我们通过添加关于所遇到的对象和结构元素的细节，以及代理的本地化来处理复杂的3D环境，从而增加DQN的第一人称原始图像输入数据。

这是一个二维地图\(自上而下的视图\)，编码三个不同的信息源: 1 \)静态结构和障碍物的位置，如墙壁，2 \)代理的位置和方向，3 \)重要物体的位置和类别标签，如医疗包、武器和敌人。



![](../../.gitbook/assets/image%20%289%29.png)

当探测器探索环境时，我们同时估计探测器和障碍物（例如墙壁）的定位，以便从每个帧的第一人称视角构建周围3D环境的地图。 同时，我们检测场景中的重要物体，如武器和弹药。 并且由于我们希望最小化增强代表的维度以允许更有效的学习，我们将所有语义信息投影到具有固定大小的单个公共2D地图上。 基本上是一个“平面图”，其中包含对象和代理的位置。 这是通过以热图的形式通过不同的灰度值对不同的性质进行编码来实现的。

我们还希望提供有关环境中存在的各种对象的代理语义信息。 对于毁灭战士，我们编码以下五个对象类别：怪物（红色），医疗包（紫色），高级武器（紫色），高级弹药（蓝色），其他武器和其他弹药（黄色） 。

### Recognition and Reconstruction

![](../../.gitbook/assets/image%20%28141%29.png)

一旦我们有了相机姿势和一个物体蒙版深度图，我们就可以在地图上投影当前帧。

## 测试

![](../../.gitbook/assets/image%20%28142%29.png)







