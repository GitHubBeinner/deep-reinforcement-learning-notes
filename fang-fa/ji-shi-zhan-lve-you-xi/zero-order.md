# Zero Order

## 介绍

> [Episodic exploration for deep deterministic policies: An application to starcraft micromanagement tasks](https://arxiv.org/abs/1609.02993)

我们将实时战略游戏“星际争霸”中的场景视为强化学习算法的新基准。我们提出微观管理任务，即军队成员在战斗中的短期，低级别控制问题。从强化学习的角度来看，这些场景具有挑战性，因为状态-动作空间非常大，并且因为状态-动作评估函数没有明显的特征表示。我们描述了用深度神经网络控制器从游戏引擎给出的原始状态特性中解决微观管理问题的方法。此外，我们还提出了一种启发式强化学习算法，该算法结合了策略空间的直接探索和反向传播。这种算法允许使用确定性策略收集学习轨迹，这似乎比greedy探索更有效。实验表明，利用该算法，我们成功地学习了15个智能体组成的军队场景中的非平凡策略，在这些场景中，问题学习和强化都在进行斗争。

## 方法

 

