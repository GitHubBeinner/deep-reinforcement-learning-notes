# Combining strategic learning and tactical search in real-time strategy games

## 介绍

> [Combining strategic learning and tactical search in real-time strategy games](https://arxiv.org/abs/1709.03480)

在实时策略（RTS）游戏中管理AI复杂性的常用技术是使用动作和/或状态抽象。高层次的抽象通常会导致良好的战略决策，但战术决策质量可能会因细节丢失而受损。一种竞争性的方法是对搜索空间进行采样，这通常会在简单的场景中带来良好的战术性能，但高层规划较差。

我们建议使用深度卷积神经网络在一组有限的抽象选择中进行选择，并利用博弈树搜索的剩余计算时间来改进低层策略。CNN通过监督学习对由Puppet Search进行标记的游戏状态进行训练，这是一种使用动作抽象的战略搜索算法。然后，网络用于选择一个脚本和抽象操作，为所有单元生成低层操作。随后，游戏树搜索算法仅考虑靠近对手单位的单位，使用游戏状态的有限视图来改进单位子集的实际动作。

在μRTS游戏中的实验表明，组合算法比其两个独立组件和其他最先进的μRTS代理中的任何一个产生更高的赢率。据我们所知，这是第一次在标准游戏地图上成功应用卷积网络来玩完整的即时战略游戏，因为以前的工作集中在子问题上，例如战斗，或者非常小的地图上。

## 方法





